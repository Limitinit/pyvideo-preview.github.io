<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="/" rel="alternate"></link><link href="/feeds/speaker_steven-kolawole.atom.xml" rel="self"></link><id>/</id><updated>2022-05-11T00:00:00+00:00</updated><entry><title>Building a Sign-to-Speech prototype with TensorFlow, Pytorch and DeepStack: How...</title><link href="/pycon-de-2022/building-a-sign-to-speech-prototype-with-tensorflow-pytorch-and-deepstack-how.html" rel="alternate"></link><published>2022-05-11T00:00:00+00:00</published><updated>2022-05-11T00:00:00+00:00</updated><author><name>Steven Kolawole</name></author><id>tag:,2022-05-11:pycon-de-2022/building-a-sign-to-speech-prototype-with-tensorflow-pytorch-and-deepstack-how.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Speaker:: Steven Kolawole&lt;/p&gt;
&lt;p&gt;Track: PyData: Computer Vision
Building an E2E working prototype that detects sign language meanings in images/videos and generates equivalent, realistic voice of words communicated by the sign language, in real-time, won't be completed in a day's work. Here I'd explain how it happened and what I learned in the process.&lt;/p&gt;
&lt;p&gt;Recorded at the PyConDE &amp;amp; PyData Berlin 2022 conference, April 11-13 2022.
&lt;a class="reference external" href="https://2022.pycon.de"&gt;https://2022.pycon.de&lt;/a&gt;
More details at the conference page: &lt;a class="reference external" href="https://2022.pycon.de/program/WWPUGX"&gt;https://2022.pycon.de/program/WWPUGX&lt;/a&gt;
Twitter: &lt;a class="reference external" href="https://twitter.com/pydataberlin"&gt;https://twitter.com/pydataberlin&lt;/a&gt;
Twitter: &lt;a class="reference external" href="https://twitter.com/pyconde"&gt;https://twitter.com/pyconde&lt;/a&gt;&lt;/p&gt;
</summary><category term="PyCon"></category><category term="PyConDE"></category><category term="pyconde2022"></category><category term="pydata"></category><category term="PyDataBerlin"></category><category term="pydataberlin2022"></category></entry><entry><title>Streamlit: The Fastest Way To Build Data Apps</title><link href="/python-web-conf-2021/streamlit-the-fastest-way-to-build-data-apps.html" rel="alternate"></link><published>2021-03-22T00:00:00+00:00</published><updated>2021-03-22T00:00:00+00:00</updated><author><name>Steven Kolawole</name></author><id>tag:,2021-03-22:python-web-conf-2021/streamlit-the-fastest-way-to-build-data-apps.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;&amp;quot;Streamlit: The Fastest Way To Build Data Apps&amp;quot; by: Steven Kolawole
When we think about building Python-based data science apps, we think Flask. But there is a better option now. Streamlit.&lt;/p&gt;
&lt;p&gt;Streamlit is an open-source web framework that lets you create apps for your machine learning projects with deceptively simple Python scripts, in hours. It supports hot-reloading, so your app updates live as you edit and save your file. No need to mess with HTTP requests, HTML, JavaScript, etc. In a short sentence, there is no need to write any front-end code. All you need is your favorite editor and a browser.&lt;/p&gt;
&lt;p&gt;In this talk, weâ€™ll go through how to build a very simple Streamlit app step-by-step. I will also review the pros and cons of Streamlit, as regards to other popular Python web frameworks being used by Data Scientists and ML Engineers.&lt;/p&gt;
&lt;p&gt;Recorded at the 2021 Python Web Conference (&lt;a class="reference external" href="https://2021.pythonwebconf.com"&gt;https://2021.pythonwebconf.com&lt;/a&gt;)&lt;/p&gt;
</summary><category term="PythonWebConf"></category><category term="PythonWebConf2021"></category></entry></feed>