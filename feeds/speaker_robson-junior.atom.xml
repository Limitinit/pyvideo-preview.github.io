<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>PyVideo.org</title><link href="/" rel="alternate"></link><link href="/feeds/speaker_robson-junior.atom.xml" rel="self"></link><id>/</id><updated>2020-07-23T00:00:00+00:00</updated><entry><title>Mastering a data pipeline with Python: 6 years of learned lessons from mistakes</title><link href="/europython-2020/mastering-a-data-pipeline-with-python-6-years-of-learned-lessons-from-mistakes.html" rel="alternate"></link><published>2020-07-23T00:00:00+00:00</published><updated>2020-07-23T00:00:00+00:00</updated><author><name>Robson Junior</name></author><id>tag:,2020-07-23:europython-2020/mastering-a-data-pipeline-with-python-6-years-of-learned-lessons-from-mistakes.html</id><summary type="html">&lt;h3&gt;Description&lt;/h3&gt;&lt;p&gt;Building data pipelines are a consolidated task, there are a vast number of tools that automate and help developers to create data pipelines with few clicks on the cloud. It might solve non-complex or well-defined standard problems. This presentation is a demystification of years of experience and painful mistakes using Python as a core to create reliable data pipelines and manage insanely amount of valuable data. Let's cover how each piece fits into this puzzle: data acquisition, ingestion, transformation, storage, workflow management and serving. Also, we'll walk through best practices and possible issues. We'll cover PySpark vs Dask and Pandas, Airflow, and Apache Arrow as a new approach.&lt;/p&gt;
</summary><category term="europython"></category><category term="europython-2020"></category><category term="europython-online"></category><category term="Beginners"></category><category term="Big Data"></category><category term="Case Study"></category><category term="Data Science"></category><category term="Open-Source"></category></entry></feed>